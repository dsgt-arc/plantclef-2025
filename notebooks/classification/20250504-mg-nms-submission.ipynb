{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80f39c3",
   "metadata": {},
   "source": [
    "# Non-Maximum Supression Submission\n",
    "\n",
    "Get the dataframe `detection/inference_outputs` with the probabilities from the detections and make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb6161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db986fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/04 22:50:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/04 22:50:13 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://atl1-1-03-006-3-0.pace.gatech.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>clef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffbf590d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plantclef.spark import get_spark\n",
    "\n",
    "spark = get_spark(cores=4)\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f407e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  4 10:50:16 PM EDT 2025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get list of stored filed in cloud bucket\n",
    "root = Path(os.path.expanduser(\"~\"))\n",
    "! date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a426a8",
   "metadata": {},
   "source": [
    "### Grounding DINO NMS probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "428889c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image_name: string (nullable = true)\n",
      " |-- probabilities: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------------------------------------\n",
      " image_name    | CBN-Pla-C6-20200814.jpg                                                          \n",
      " probabilities | [2.406519342912361E-5, 1.1829448339994997E-5, 4.4492684537544847E-5, 7.187668... \n",
      "-RECORD 1-----------------------------------------------------------------------------------------\n",
      " image_name    | GUARDEN-CBNMed-19-5-15-44-20240429.jpg                                           \n",
      " probabilities | [3.263013422838412E-5, 3.4224908631586004E-6, 4.886940587311983E-5, 1.0735976... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path and dataset names\n",
    "data_path = f\"{root}/p-dsgt_clef2025-0/shared/plantclef/data\"\n",
    "inference_path = f\"{data_path}/detection/inference_outputs\"\n",
    "df = spark.read.parquet(inference_path)\n",
    "df.printSchema()\n",
    "df.show(n=2, vertical=True, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea1058b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17053"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f81ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plantclef.config import get_class_mappings_file\n",
    "\n",
    "\n",
    "def load_class_mapping(class_mapping_file=None):\n",
    "    with open(class_mapping_file) as f:\n",
    "        class_index_to_class_name = {i: line.strip() for i, line in enumerate(f)}\n",
    "    return class_index_to_class_name\n",
    "\n",
    "\n",
    "# load class mappings\n",
    "class_mapping_file = get_class_mappings_file()\n",
    "cid_to_spid = load_class_mapping(class_mapping_file)\n",
    "\n",
    "\n",
    "# get top-K predictions for each row\n",
    "def get_top_n_predictions(probabilities: list, n=5) -> list[int]:\n",
    "    proba_arr = np.array(probabilities)\n",
    "    top_n_indices = proba_arr.argsort()[-n:][::-1]  # fastest way to get top n indices\n",
    "    return [cid_to_spid[i] for i in top_n_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7681ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pandas_df = df.toPandas()\n",
    "\n",
    "top_k = 1\n",
    "pandas_df[\"species_ids\"] = pandas_df[\"probabilities\"].apply(\n",
    "    lambda proba: get_top_n_predictions(proba, n=top_k)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e3c055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>species_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBN-Pla-C6-20200814.jpg</td>\n",
       "      <td>[2.406519342912361e-05, 1.1829448339994997e-05...</td>\n",
       "      <td>[1390793]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GUARDEN-CBNMed-19-5-15-44-20240429.jpg</td>\n",
       "      <td>[3.263013422838412e-05, 3.4224908631586004e-06...</td>\n",
       "      <td>[1396063]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBN-Pla-C5-20140902.jpg</td>\n",
       "      <td>[4.0722519770497456e-05, 2.578282328613568e-05...</td>\n",
       "      <td>[1394311]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBN-Pla-C2-20180906.jpg</td>\n",
       "      <td>[3.5486275464791106e-06, 8.165693543560337e-06...</td>\n",
       "      <td>[1361281]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBN-PdlC-D6-20150701.jpg</td>\n",
       "      <td>[1.8766439097817056e-05, 1.579140189278405e-05...</td>\n",
       "      <td>[1393679]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GUARDEN-CBNMed-14-4-9-49-20240429.jpg</td>\n",
       "      <td>[0.0011196996783837676, 0.00026946881553158164...</td>\n",
       "      <td>[1741834]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBN-PdlC-F2-20190909.jpg</td>\n",
       "      <td>[2.3464181140298024e-06, 7.250819180626422e-06...</td>\n",
       "      <td>[1742052]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBN-PdlC-E1-20140901.jpg</td>\n",
       "      <td>[5.5319997045444325e-05, 1.1587068001972511e-0...</td>\n",
       "      <td>[1394311]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBN-Pla-A4-20190814.jpg</td>\n",
       "      <td>[8.435828021902125e-06, 1.4364024536916986e-05...</td>\n",
       "      <td>[1414270]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CBN-PdlC-F5-20140630.jpg</td>\n",
       "      <td>[2.0208362911944278e-06, 4.054568307765294e-06...</td>\n",
       "      <td>[1664563]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_name  \\\n",
       "0                 CBN-Pla-C6-20200814.jpg   \n",
       "1  GUARDEN-CBNMed-19-5-15-44-20240429.jpg   \n",
       "2                 CBN-Pla-C5-20140902.jpg   \n",
       "3                 CBN-Pla-C2-20180906.jpg   \n",
       "4                CBN-PdlC-D6-20150701.jpg   \n",
       "5   GUARDEN-CBNMed-14-4-9-49-20240429.jpg   \n",
       "6                CBN-PdlC-F2-20190909.jpg   \n",
       "7                CBN-PdlC-E1-20140901.jpg   \n",
       "8                 CBN-Pla-A4-20190814.jpg   \n",
       "9                CBN-PdlC-F5-20140630.jpg   \n",
       "\n",
       "                                       probabilities species_ids  \n",
       "0  [2.406519342912361e-05, 1.1829448339994997e-05...   [1390793]  \n",
       "1  [3.263013422838412e-05, 3.4224908631586004e-06...   [1396063]  \n",
       "2  [4.0722519770497456e-05, 2.578282328613568e-05...   [1394311]  \n",
       "3  [3.5486275464791106e-06, 8.165693543560337e-06...   [1361281]  \n",
       "4  [1.8766439097817056e-05, 1.579140189278405e-05...   [1393679]  \n",
       "5  [0.0011196996783837676, 0.00026946881553158164...   [1741834]  \n",
       "6  [2.3464181140298024e-06, 7.250819180626422e-06...   [1742052]  \n",
       "7  [5.5319997045444325e-05, 1.1587068001972511e-0...   [1394311]  \n",
       "8  [8.435828021902125e-06, 1.4364024536916986e-05...   [1414270]  \n",
       "9  [2.0208362911944278e-06, 4.054568307765294e-06...   [1664563]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2abf314",
   "metadata": {},
   "source": [
    "### group predictions by `image_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d0d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4062527/115649718.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: aggregate_predictions(group, k=TOP_K))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quadrat_id</th>\n",
       "      <th>species_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-CEV3-20240602.jpg</td>\n",
       "      <td>[1360187, 1395111, 1450109, 1743159, 1398690, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBN-PdlC-A1-20130807.jpg</td>\n",
       "      <td>[1392608, 1742100, 1392407, 1412857, 1362331, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBN-PdlC-A1-20130903.jpg</td>\n",
       "      <td>[1392608, 1397468, 1412857, 1742052, 1394311, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBN-PdlC-A1-20140721.jpg</td>\n",
       "      <td>[1394911, 1412857, 1361389, 1397449, 1654153, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBN-PdlC-A1-20140811.jpg</td>\n",
       "      <td>[1392608, 1412857, 1394911, 1395807]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 quadrat_id                                        species_ids\n",
       "0    2024-CEV3-20240602.jpg  [1360187, 1395111, 1450109, 1743159, 1398690, ...\n",
       "1  CBN-PdlC-A1-20130807.jpg  [1392608, 1742100, 1392407, 1412857, 1362331, ...\n",
       "2  CBN-PdlC-A1-20130903.jpg  [1392608, 1397468, 1412857, 1742052, 1394311, ...\n",
       "3  CBN-PdlC-A1-20140721.jpg  [1394911, 1412857, 1361389, 1397449, 1654153, ...\n",
       "4  CBN-PdlC-A1-20140811.jpg               [1392608, 1412857, 1394911, 1395807]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def aggregate_predictions(group, k: int = 10):\n",
    "    # flatten the list of predictions across duplicate rows\n",
    "    all_preds = list(chain.from_iterable(group[\"species_ids\"]))\n",
    "    # count and get top-k predictions\n",
    "    top_preds = [spid for spid, _ in Counter(all_preds).most_common(k)]\n",
    "    return pd.Series({\"species_ids\": top_preds})\n",
    "\n",
    "\n",
    "# group by image_name and aggregate predictions\n",
    "TOP_K = 10\n",
    "aggregated_df = (\n",
    "    pandas_df.groupby(\"image_name\")\n",
    "    .apply(lambda group: aggregate_predictions(group, k=TOP_K))\n",
    "    .reset_index()\n",
    ")\n",
    "aggregated_df = aggregated_df.rename(columns={\"image_name\": \"quadrat_id\"})\n",
    "\n",
    "aggregated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67deb53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=======================================================> (74 + 2) / 76]\r"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "test_path = f\"{data_path}/parquet/test_2025\"\n",
    "test_df = spark.read.parquet(test_path).toPandas()\n",
    "test_df = test_df.rename(columns={\"image_name\": \"quadrat_id\"})\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ac915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join with aggregated_df to fill in missing quadrat_ids\n",
    "merged_df = pd.merge(\n",
    "    test_df[[\"quadrat_id\"]],\n",
    "    aggregated_df,\n",
    "    on=\"quadrat_id\",\n",
    "    how=\"outer\",\n",
    ")\n",
    "final_df = merged_df[[\"quadrat_id\", \"species_ids\"]]\n",
    "# fill NaN values with empty lists\n",
    "final_df[\"species_ids\"] = final_df[\"species_ids\"].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "# remove .jpg extension from quadrat_id\n",
    "final_df[\"quadrat_id\"] = final_df[\"quadrat_id\"].str.replace(\".jpg\", \"\", regex=False)\n",
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aggregated_df), len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099487a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def format_species_ids(species_ids: list) -> str:\n",
    "    \"\"\"Formats the species IDs in single square brackets, separated by commas.\"\"\"\n",
    "    formatted_ids = \", \".join(str(id) for id in species_ids if id is not None)\n",
    "    return f\"[{formatted_ids}]\"\n",
    "\n",
    "\n",
    "def prepare_and_write_submission(pandas_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Converts Spark DataFrame to Pandas, formats it, and writes to GCS.\"\"\"\n",
    "    records = []\n",
    "    for _, row in pandas_df.iterrows():\n",
    "        logits = row[\"species_ids\"]\n",
    "        formatted_species = format_species_ids(logits)\n",
    "        records.append(\n",
    "            {\"quadrat_id\": row[\"quadrat_id\"], \"species_ids\": formatted_species}\n",
    "        )\n",
    "\n",
    "    pandas_df = pd.DataFrame(records)\n",
    "    return pandas_df\n",
    "\n",
    "\n",
    "def get_plantclef_dir() -> str:\n",
    "    home_dir = Path(os.path.expanduser(\"~\"))\n",
    "    return f\"{home_dir}/p-dsgt_clef2025-0/shared/plantclef/\"\n",
    "\n",
    "\n",
    "def write_csv_to_pace(df, file_name: str, testset_name: str):\n",
    "    \"\"\"Writes the Pandas DataFrame to a CSV file on PACE.\"\"\"\n",
    "\n",
    "    # prepare and write the submission\n",
    "    submission_df = prepare_and_write_submission(df)\n",
    "    project_dir = get_plantclef_dir()\n",
    "    submission_path = f\"{project_dir}/submissions/detection/{testset_name}\"\n",
    "    output_path = f\"{submission_path}/{file_name}\"\n",
    "    # ensure directory exists before saving\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    # write to CSV\n",
    "    submission_df.to_csv(output_path, sep=\",\", index=False, quoting=csv.QUOTE_ALL)\n",
    "    print(f\"Submission file saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def main(df_final: pd.DataFrame, file_name: str, testset_name: str = \"test_2025\"):\n",
    "    # write CSV file to PACE\n",
    "    write_csv_to_pace(df_final, file_name, testset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff02a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"groundingdino_nms_topk{TOP_K}_dsgt.csv\"\n",
    "main(final_df, file_name, testset_name=\"test_2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f1a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
