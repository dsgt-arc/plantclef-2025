{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff54092",
   "metadata": {},
   "source": [
    "# Non-Maximum Supression Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d5aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62b0e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/04 18:53:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/04 18:53:28 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://atl1-1-03-006-3-0.pace.gatech.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>clef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffbf594d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plantclef.spark import get_spark\n",
    "\n",
    "spark = get_spark(cores=4)\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053905f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  4 06:53:31 PM EDT 2025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get list of stored filed in cloud bucket\n",
    "root = Path(os.path.expanduser(\"~\"))\n",
    "! date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57270cb",
   "metadata": {},
   "source": [
    "### NMS detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6093b37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image_name: string (nullable = true)\n",
      " |-- output: struct (nullable = true)\n",
      " |    |-- extracted_bbox: array (nullable = true)\n",
      " |    |    |-- element: binary (containsNull = true)\n",
      " |    |-- boxes: array (nullable = true)\n",
      " |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |-- scores: array (nullable = true)\n",
      " |    |    |-- element: float (containsNull = true)\n",
      " |    |-- text_labels: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- sample_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path and dataset names\n",
    "data_path = f\"{root}/p-dsgt_clef2025-0/shared/plantclef/data\"\n",
    "detect_path = f\"{data_path}/detection/test_2025/test_2025_detection_v1\"\n",
    "detection_df = spark.read.parquet(detect_path)\n",
    "detection_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e1f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2105"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a98ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image_name: string (nullable = true)\n",
      " |-- extracted_bbox: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# explode the extracted_bbox list so each row has one bounding box\n",
    "exploded_df = (\n",
    "    detection_df.select(\n",
    "        \"image_name\", F.explode(\"output.extracted_bbox\").alias(\"extracted_bbox\")\n",
    "    )\n",
    "    .repartition(100, \"image_name\")\n",
    "    .persist()\n",
    ")\n",
    "display(exploded_df.count())\n",
    "exploded_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63189ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from plantclef.serde import deserialize_image\n",
    "from plantclef.config import get_class_mappings_file\n",
    "from plantclef.model_setup import setup_fine_tuned_model\n",
    "\n",
    "\n",
    "def load_class_mapping(class_mapping_file=None):\n",
    "    with open(class_mapping_file) as f:\n",
    "        class_index_to_class_name = {i: line.strip() for i, line in enumerate(f)}\n",
    "    return class_index_to_class_name\n",
    "\n",
    "\n",
    "num_classes = 7806  # total number of plant species\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model(\n",
    "    \"vit_base_patch14_reg4_dinov2.lvd142m\",\n",
    "    pretrained=False,\n",
    "    num_classes=num_classes,\n",
    "    checkpoint_path=setup_fine_tuned_model(),\n",
    ")\n",
    "# data transform\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "# move model to GPU if available\n",
    "model.to(device)\n",
    "model.eval()\n",
    "# path for class_mappings.txt file\n",
    "class_mapping_file = get_class_mappings_file()\n",
    "\n",
    "\n",
    "# load class mappings\n",
    "cid_to_spid = load_class_mapping(class_mapping_file)\n",
    "\n",
    "\n",
    "def make_predict_fn():\n",
    "    \"\"\"Return UDF using a closure over the model\"\"\"\n",
    "\n",
    "    def predict(input_data):\n",
    "        img = deserialize_image(input_data)  # from bytes to PIL image\n",
    "        processed_image = transforms(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(processed_image)\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        return probabilities[0].cpu().numpy().tolist()\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d39c2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create UDF\n",
    "predict_fn = make_predict_fn()\n",
    "\n",
    "# get subset of data for testing\n",
    "subset_pd = exploded_df.limit(20).toPandas()\n",
    "subset_pd[\"probabilities\"] = subset_pd[\"extracted_bbox\"].apply(predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c571bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>extracted_bbox</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[2.6421303118695505e-06, 3.864691393573594e-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[4.0289813796334784e-07, 3.7558137933046964e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[4.55143845101702e-06, 5.1167003221053164e-06,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[6.224210210348247e-06, 1.1222463399462868e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[3.508395707285672e-07, 6.856546406197594e-07,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_name  \\\n",
       "0  CBN-PdlC-D3-20200722.jpg   \n",
       "1  CBN-PdlC-D3-20200722.jpg   \n",
       "2  CBN-PdlC-D3-20200722.jpg   \n",
       "3  CBN-PdlC-D3-20200722.jpg   \n",
       "4  CBN-PdlC-D3-20200722.jpg   \n",
       "\n",
       "                                      extracted_bbox  \\\n",
       "0  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "1  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "2  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "3  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "4  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "\n",
       "                                       probabilities  \n",
       "0  [2.6421303118695505e-06, 3.864691393573594e-07...  \n",
       "1  [4.0289813796334784e-07, 3.7558137933046964e-0...  \n",
       "2  [4.55143845101702e-06, 5.1167003221053164e-06,...  \n",
       "3  [6.224210210348247e-06, 1.1222463399462868e-05...  \n",
       "4  [3.508395707285672e-07, 6.856546406197594e-07,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(subset_pd.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135aaa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.6421303118695505e-06,\n",
       " 3.864691393573594e-07,\n",
       " 2.1716316496167565e-06,\n",
       " 1.0423846106277779e-06,\n",
       " 2.137569936166983e-06,\n",
       " 5.375565160647966e-05,\n",
       " 0.00014674248814117163,\n",
       " 4.8739006160758436e-05,\n",
       " 0.0016026853118091822,\n",
       " 0.001182828564196825]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_pd[\"probabilities\"].iloc[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa66005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# get top-K predictions for each row\n",
    "def get_top_n_predictions(probabilities: list, n=5):\n",
    "    proba_arr = np.array(probabilities)\n",
    "    top_n_indices = proba_arr.argsort()[-n:][::-1]  # fastest way to get top n indices\n",
    "    return [(cid_to_spid[i], probabilities[i]) for i in top_n_indices]\n",
    "\n",
    "\n",
    "top_k = 10\n",
    "subset_pd[f\"top_{top_k}_predictions\"] = subset_pd[\"probabilities\"].apply(\n",
    "    lambda proba: get_top_n_predictions(proba, n=top_k)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac5e56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1622901', 0.06579609960317612),\n",
       " ('1396439', 0.06303632259368896),\n",
       " ('1396408', 0.028585851192474365),\n",
       " ('1398779', 0.02830541878938675),\n",
       " ('1418211', 0.024407442659139633),\n",
       " ('1647128', 0.016660762950778008),\n",
       " ('1647677', 0.014911099337041378),\n",
       " ('1412857', 0.013472514227032661),\n",
       " ('1647150', 0.012758580036461353),\n",
       " ('1722440', 0.011723535135388374)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_pd[f\"top_{top_k}_predictions\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5e4c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>extracted_bbox</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>top_10_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[2.6421303118695505e-06, 3.864691393573594e-07...</td>\n",
       "      <td>[(1622901, 0.06579609960317612), (1396439, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[4.0289813796334784e-07, 3.7558137933046964e-0...</td>\n",
       "      <td>[(1396408, 0.7895054817199707), (1396362, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[4.55143845101702e-06, 5.1167003221053164e-06,...</td>\n",
       "      <td>[(1425722, 0.048355188220739365), (1396408, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[6.224210210348247e-06, 1.1222463399462868e-05...</td>\n",
       "      <td>[(1396408, 0.07225219160318375), (1425722, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBN-PdlC-D3-20200722.jpg</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>[3.508395707285672e-07, 6.856546406197594e-07,...</td>\n",
       "      <td>[(1396408, 0.26717033982276917), (1399082, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_name  \\\n",
       "0  CBN-PdlC-D3-20200722.jpg   \n",
       "1  CBN-PdlC-D3-20200722.jpg   \n",
       "2  CBN-PdlC-D3-20200722.jpg   \n",
       "3  CBN-PdlC-D3-20200722.jpg   \n",
       "4  CBN-PdlC-D3-20200722.jpg   \n",
       "\n",
       "                                      extracted_bbox  \\\n",
       "0  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "1  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "2  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "3  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "4  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       "\n",
       "                                       probabilities  \\\n",
       "0  [2.6421303118695505e-06, 3.864691393573594e-07...   \n",
       "1  [4.0289813796334784e-07, 3.7558137933046964e-0...   \n",
       "2  [4.55143845101702e-06, 5.1167003221053164e-06,...   \n",
       "3  [6.224210210348247e-06, 1.1222463399462868e-05...   \n",
       "4  [3.508395707285672e-07, 6.856546406197594e-07,...   \n",
       "\n",
       "                                  top_10_predictions  \n",
       "0  [(1622901, 0.06579609960317612), (1396439, 0.0...  \n",
       "1  [(1396408, 0.7895054817199707), (1396362, 0.01...  \n",
       "2  [(1425722, 0.048355188220739365), (1396408, 0....  \n",
       "3  [(1396408, 0.07225219160318375), (1425722, 0.0...  \n",
       "4  [(1396408, 0.26717033982276917), (1399082, 0.0...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e203b0",
   "metadata": {},
   "source": [
    "### scalable pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6544ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write 500 partitions of the exploded dataframe to parquet\n",
    "output_dir = (\n",
    "    f\"{root}/p-dsgt_clef2025-0/shared/plantclef/data/detection/batched_extracted_bbox\"\n",
    ")\n",
    "exploded_df.repartition(200).write.mode(\"overwrite\").parquet(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90f7f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run_batch_inference(spark, input_path, output_path):\n",
    "    df = spark.read.parquet(input_path).toPandas()\n",
    "    predict_fn = make_predict_fn()\n",
    "    df[\"probabilities\"] = df[\"extracted_bbox\"].apply(predict_fn)\n",
    "    df[[\"image_name\", \"probabilities\"]].to_parquet(output_path, index=False)\n",
    "\n",
    "\n",
    "def run_inference_on_all_batches(spark, input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    parquet_files = sorted([f for f in os.listdir(input_dir) if f.endswith(\".parquet\")])\n",
    "\n",
    "    for fname in tqdm(parquet_files, desc=\"Running inference on batches\"):\n",
    "        input_path = os.path.join(input_dir, fname)\n",
    "        output_path = os.path.join(\n",
    "            output_dir, fname.replace(\".parquet\", \"_out.parquet\")\n",
    "        )\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            continue  # Skip if already processed\n",
    "\n",
    "        run_batch_inference(spark, input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "281336ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on batches: 100%|██████████| 200/200 [30:44<00:00,  9.22s/it] \n"
     ]
    }
   ],
   "source": [
    "input_dir = (\n",
    "    f\"{root}/p-dsgt_clef2025-0/shared/plantclef/data/detection/batched_extracted_bbox\"\n",
    ")\n",
    "output_dir = (\n",
    "    f\"{root}/p-dsgt_clef2025-0/shared/plantclef/data/detection/inference_outputs\"\n",
    ")\n",
    "\n",
    "run_inference_on_all_batches(spark, input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11f8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
