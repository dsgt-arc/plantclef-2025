{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a59db57",
   "metadata": {},
   "source": [
    "# Single-label image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d95e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad60cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/16 13:40:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/16 13:40:09 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://atl1-1-02-005-31-0.pace.gatech.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>clef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffbf590d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plantclef.spark import get_spark\n",
    "\n",
    "spark = get_spark(cores=4)\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6dba41",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8074208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 16 01:40:11 PM EDT 2025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get list of stored filed in cloud bucket\n",
    "root = Path(os.path.expanduser(\"~\"))\n",
    "! date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e9a77",
   "metadata": {},
   "source": [
    "### test embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909f3b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image_name: string (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- data: binary (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|          image_name|                path|                data|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|CBN-Pla-B3-201907...|/test/data/PlantC...|[FF D8 FF E0 00 1...|\n",
      "|CBN-PdlC-E5-20180...|/test/data/PlantC...|[FF D8 FF E0 00 1...|\n",
      "|CBN-PdlC-B1-20140...|/test/data/PlantC...|[FF D8 FF E0 00 1...|\n",
      "|CBN-Pla-D4-201507...|/test/data/PlantC...|[FF D8 FF E0 00 1...|\n",
      "|CBN-PdlC-F3-20190...|/test/data/PlantC...|[FF D8 FF E0 00 1...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path and dataset names\n",
    "data_path = f\"{root}/p-dsgt_clef2025-0/shared/plantclef/data/parquet\"\n",
    "\n",
    "# Define the path to the parquet files\n",
    "test_path = f\"{data_path}/test_2025\"\n",
    "\n",
    "# Read the parquet files into a spark DataFrame\n",
    "test_df = spark.read.parquet(test_path)\n",
    "\n",
    "# Show the data\n",
    "test_df.printSchema()\n",
    "test_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c079f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=768, out_features=7806, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from plantclef.model_setup import setup_fine_tuned_model\n",
    "\n",
    "\n",
    "num_classes = 7806  # total number of plant species\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model(\n",
    "    \"vit_base_patch14_reg4_dinov2.lvd142m\",\n",
    "    pretrained=False,\n",
    "    num_classes=num_classes,\n",
    "    checkpoint_path=setup_fine_tuned_model(),\n",
    ")\n",
    "# Data transform\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "# Move model to GPU if available\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f800394f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>kmeans_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBN-Pla-A1-20190814.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBN-Pla-D6-20190814.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBN-PdlC-C5-20140901.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LISAH-BOU-0-37-20230512.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBN-Pla-E4-20130808.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_name  kmeans_cluster\n",
       "0      CBN-Pla-A1-20190814.jpg               2\n",
       "1      CBN-Pla-D6-20190814.jpg               2\n",
       "2     CBN-PdlC-C5-20140901.jpg               1\n",
       "3  LISAH-BOU-0-37-20230512.jpg               0\n",
       "4      CBN-Pla-E4-20130808.jpg               2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dominant_cluster</th>\n",
       "      <th>renormalized_probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2.3629971e-05, 4.4991793e-05, 4.332371e-05, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[2.4171377e-05, 2.2901053e-05, 1.4540791e-05, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[5.1414485e-05, 0.00010827277, 0.00010225503, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dominant_cluster                         renormalized_probabilities\n",
       "0                 1  [2.3629971e-05, 4.4991793e-05, 4.332371e-05, 1...\n",
       "1                 2  [2.4171377e-05, 2.2901053e-05, 1.4540791e-05, ...\n",
       "2                 0  [5.1414485e-05, 0.00010827277, 0.00010225503, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# load the cluster probabilities dataframes\n",
    "def get_cluster_probability_dfs():\n",
    "    clustering_path = \"~/p-dsgt_clef2025-0/shared/plantclef/data/clustering\"\n",
    "    test_cluster_csv = f\"{clustering_path}/test_2025_dominant_clusters.csv\"\n",
    "    test_cluster_probabilities = (\n",
    "        f\"{clustering_path}/test_2025_embed_probabilities_clustered\"\n",
    "    )\n",
    "    cluster_df = pd.read_csv(test_cluster_csv)\n",
    "    probabilities_df = pd.read_parquet(test_cluster_probabilities)\n",
    "    return cluster_df, probabilities_df\n",
    "\n",
    "\n",
    "def get_prior_for_image(image_name, cluster_df, probabilities_df) -> dict:\n",
    "    row = cluster_df[cluster_df[\"image_name\"] == image_name]\n",
    "    cluster_id = row.iloc[0][\"kmeans_cluster\"]\n",
    "    prior_row = probabilities_df[probabilities_df[\"dominant_cluster\"] == cluster_id]\n",
    "    return prior_row.iloc[0][\"renormalized_probabilities\"]\n",
    "\n",
    "\n",
    "cluster_df, probabilities_df = get_cluster_probability_dfs()\n",
    "display(cluster_df.head(5))\n",
    "display(probabilities_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76512ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantclef.config import get_class_mappings_file\n",
    "\n",
    "use_grid = True\n",
    "use_prior = True\n",
    "\n",
    "\n",
    "def load_class_mapping(class_mapping_file):\n",
    "    with open(class_mapping_file) as f:\n",
    "        class_index_to_class_name = {i: line.strip() for i, line in enumerate(f)}\n",
    "    return class_index_to_class_name\n",
    "\n",
    "\n",
    "def split_into_grid(image, grid_size=4):\n",
    "    w, h = image.size\n",
    "    grid_w, grid_h = w // grid_size, h // grid_size\n",
    "    images = []\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            left = i * grid_w\n",
    "            upper = j * grid_h\n",
    "            right = left + grid_w\n",
    "            lower = upper + grid_h\n",
    "            crop_image = image.crop((left, upper, right, lower))\n",
    "            images.append(crop_image)\n",
    "    return images\n",
    "\n",
    "\n",
    "class_mapping_file = get_class_mappings_file()\n",
    "cid_to_spid = load_class_mapping(class_mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: CBN-Pla-B3-20190723.jpg\n",
      "image data: <class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "image data shape: (3500, 3184)\n"
     ]
    }
   ],
   "source": [
    "from plantclef.serde import deserialize_image\n",
    "\n",
    "# select first image\n",
    "image_name = test_df.select(\"image_name\").first()[0]\n",
    "image_data = test_df.select(\"data\").first()[0]\n",
    "image_data = deserialize_image(image_data)\n",
    "\n",
    "print(f\"image name: {image_name}\")\n",
    "print(f\"image data: {type(image_data)}\")\n",
    "print(f\"image data shape: {image_data.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3afde54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'1361281': 0.36755260825157166},\n",
       "  {'1395807': 0.01984396018087864},\n",
       "  {'1741880': 0.0167352557182312},\n",
       "  {'1390690': 0.011740563437342644},\n",
       "  {'1741903': 0.011048056185245514},\n",
       "  {'1397565': 0.01017786841839552},\n",
       "  {'1361275': 0.006565099116414785},\n",
       "  {'1398779': 0.006193633656948805},\n",
       "  {'1414270': 0.0060384804382920265},\n",
       "  {'1396717': 0.006015494931489229}]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(\n",
    "    image_data,\n",
    "    cluster_df,\n",
    "    probabilities_df,\n",
    "    use_prior: bool = False,\n",
    "):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        img = transforms(image_data).unsqueeze(0).to(device)\n",
    "        outputs = model(img)  # unsqueeze single image into batch of 1\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        if use_prior:\n",
    "            prior = get_prior_for_image(image_name, cluster_df, probabilities_df)\n",
    "            probabilities = probabilities * torch.tensor(prior).to(device)\n",
    "        top_probs, top_indices = torch.topk(probabilities, k=10)\n",
    "        top_probs = top_probs.cpu().detach().numpy()[0]\n",
    "        top_indices = top_indices.cpu().detach().numpy()[0]\n",
    "        result = [\n",
    "            {cid_to_spid[int(index)]: float(prob)}\n",
    "            for index, prob in zip(top_indices, top_probs)\n",
    "        ]\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "original_results = predict(image_data, cluster_df, probabilities_df, use_prior=False)\n",
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdfbc6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'1361281': 0.028440652415156364},\n",
       "  {'1395807': 0.0004967988352291286},\n",
       "  {'1741880': 0.0002662691113073379},\n",
       "  {'1397565': 8.511155465384945e-05},\n",
       "  {'1396717': 5.7824050600174814e-05},\n",
       "  {'1741903': 4.429689943208359e-05},\n",
       "  {'1361275': 3.6528264899970964e-05},\n",
       "  {'1743474': 3.6276418541092426e-05},\n",
       "  {'1398779': 2.987371408380568e-05},\n",
       "  {'1397070': 2.9231074222479947e-05}]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prior results\n",
    "prior_results = predict(image_data, cluster_df, probabilities_df, use_prior=True)\n",
    "prior_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plantclef.serde import deserialize_image\n",
    "\n",
    "\n",
    "# # predict single image\n",
    "# def predict(input_data, image_name):\n",
    "#     img = deserialize_image(input_data)  # from bytes to PIL image\n",
    "#     top_k_proba = 10\n",
    "#     limit_logits = 10\n",
    "#     images = [img]\n",
    "#     # use grid to get logits\n",
    "#     if use_grid:\n",
    "#         images = split_into_grid(img)\n",
    "#     results = []\n",
    "#     for tile in images:\n",
    "#         processed_image = transforms(tile).unsqueeze(0).to(device)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(processed_image)\n",
    "#             probabilities = torch.softmax(outputs, dim=1) * 100\n",
    "#             if use_prior:\n",
    "#                 prior = get_prior_for_image(image_name)\n",
    "#                 probabilities = probabilities * torch.tensor(prior).to(device)\n",
    "#             top_probs, top_indices = torch.topk(probabilities, k=top_k_proba)\n",
    "#         top_probs = top_probs.cpu().numpy()[0]\n",
    "#         top_indices = top_indices.cpu().numpy()[0]\n",
    "\n",
    "#         result = [\n",
    "#             {cid_to_spid[index]: float(prob)}\n",
    "#             for index, prob in zip(top_indices, top_probs)\n",
    "#         ]\n",
    "#         results.append(result)\n",
    "#     # flatten the results from all grids, get top probabilities\n",
    "#     flattened_results = [item for grid in results for item in grid[:limit_logits]]\n",
    "#     # sort by score in descending order\n",
    "#     sorted_logits = sorted(flattened_results, key=lambda x: -list(x.values())[0])\n",
    "#     return sorted_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c294bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
